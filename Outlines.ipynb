{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "satisfactory-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import datetime as dt\n",
    "import itertools\n",
    "import csv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-aerospace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "### OUTLINE FOR ANALYST RANKING LEADERBOARD ###\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### History of Recommendations for stock(s) ###\n",
    "\n",
    "\n",
    "### Leaderboard Ranking based on: Accuracy, Influence, Clout, etc ###\n",
    "\n",
    "\n",
    "### Industry and Sector Forecasts ###\n",
    "\n",
    "\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "### OUTLINE FOR NEWS & OPINION POLLS ###\n",
    "\n",
    "\n",
    "##############################################################\n",
    "### NEWS ###\n",
    "\n",
    "### Relevant News Stream With Watchlist Mentions ###\n",
    "\n",
    "\n",
    "### News and Social Media Sentiment Metrics ###\n",
    "\n",
    "\n",
    "### News Aggregation Stream ###\n",
    "\n",
    "\n",
    "### Market News: IPOs, Defaults, M&A, Movements ###\n",
    "\n",
    "\n",
    "##############################################################\n",
    "### OPINION POLLS ###\n",
    "\n",
    "\n",
    "### Bull/Bear Polls ###\n",
    "\n",
    "\n",
    "### VIX & VIX Sentiment ###\n",
    "\n",
    "\n",
    "### Margin Debt Indicator ###\n",
    "\n",
    "\n",
    "### Short Interest and Short Indicators ###\n",
    "\n",
    "\n",
    "### Unusual Options Activity ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "### OUTLINE FOR STOCK INFORMATION ###\n",
    "\n",
    "\n",
    "### Stock Metrics ###\n",
    "\n",
    "\n",
    "### Information ###\n",
    "\n",
    "\n",
    "### Error Handling ###\n",
    "\n",
    "\n",
    "### Charts ###\n",
    "\n",
    "\n",
    "### Analysts Activity and Ranking ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "### OUTLINE FOR GLOBAL MOVEMENTS ###\n",
    "\n",
    "# Here we want to gather and display data from indicies around the world\n",
    "indicies = {'^GSPC': 'SP500',\n",
    "            '^IXIC': 'Nasdaq,',\n",
    "           '^VIX': 'VIX',\n",
    "           '^FTSE': 'FTSE 100 (UK)',\n",
    "           '^FCHI': 'CAC40 (FRANCE)',\n",
    "           '^N225': 'Nikkei (Japan)',\n",
    "           '^MXX': 'IPC MX (Mexico)'}\n",
    "\n",
    "tickers = indicies.keys()\n",
    "ticknames = indicies.values()\n",
    "\n",
    "def plotindicies(ticker):\n",
    "    tick = yf.Ticker(ticker)\n",
    "    index = tick.history(period='30d').Close\n",
    "    indexdf = pd.DataFrame(index)\n",
    "    plot = indexdf.plot(title = '%s 30 day view' % ticker)\n",
    "    return plot\n",
    "    \n",
    "\n",
    "\n",
    "# building our dataframe\n",
    "def globalmarkets(tickers):\n",
    "    indicies1 = pd.DataFrame(columns = ticknames)\n",
    "\n",
    "    for tick in tickers:\n",
    "        indicies = yf.Ticker(tick)\n",
    "        indicies = indicies.history(period='5y').Close\n",
    "        indicies = pd.DataFrame(indicies)\n",
    "        #indicies.columns = [tick]\n",
    "        indicies1.append(indicies)\n",
    "        # #\n",
    "        # indicies = indicies.append(indicies)\n",
    "    #closedf = pd.DataFrame(indicies)\n",
    "    \n",
    "    return indicies\n",
    "\n",
    "\n",
    "    plotindicies('MSFT')\n",
    "\n",
    "for tick in tickers:\n",
    "    plotindicies(tick)\n",
    "\n",
    "\n",
    "### Indicies Price Changes ###\n",
    "\n",
    "\n",
    "### Indicies Metrics ###\n",
    "\n",
    "\n",
    "### Sector Metrics ###\n",
    "\n",
    "\n",
    "### Sector Price Changes ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "### OUTLINE FOR GLOBAL NEWS & SENTIMENT ###\n",
    "\n",
    "\n",
    "### Global Foreign News Translator ###\n",
    "\n",
    "\n",
    "### Foreign Social Media Sentiment Monitor ###\n",
    "\n",
    "\n",
    "### Monetary Policy and Fiscal Policy News Monitor ###\n",
    "\n",
    "\n",
    "### Government Movements Monitor ###\n",
    "\n",
    "\n",
    "### Top Central Banks Movements and Bal. Sheet Changes ###\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-domain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-current",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analystrecom(ticker):\n",
    "    stock = yf.Ticker(ticker)\n",
    "    # Get recommendations from 2020 - Present\n",
    "    data1 = stock.recommendations['2020'::]\n",
    "    data2 = pd.DataFrame(data1['To Grade'])\n",
    "    # Calculate total buys, holds, sells\n",
    "    buys = data2.where((data2=='Buy') | (data2=='Overweight') | (data2=='Outperform') | (data2=='Strong Buy') | (data2=='Positive'))\n",
    "    holds = data2.where((data2=='Neutral') | (data2=='Hold') | (data2=='Market Perform') | (data2=='Equal-Weight') | (data2=='Sector Weight') | (data2=='Sector Perform'))\n",
    "    sells = data2.where((data2=='Sell') | (data2=='Underweight') | (data2=='Underperform'))\n",
    "    # Convert totals to numbers\n",
    "    num_buys = buys.count()\n",
    "    num_holds = holds.count()\n",
    "    num_sells = sells.count()\n",
    "    # Create a dataframe from them\n",
    "    # Recoms = pd.DataFrame(data = [num_buys, num_sells, num_holds], columns=['Buys','Holds', 'Sells'])\n",
    "    # Plotting\n",
    "    #fig = plt.figure()\n",
    "    #ax = fig.add_axes([0,0,1,1])\n",
    "    #values = [num_buys, num_sells, num_holds]\n",
    "    #recoms = ['Buys', 'Holds', 'Sells']\n",
    "    #ax.bar(values, recoms)\n",
    "    #plt.show()\n",
    "    Recoms = {'Buys': num_buys,'Sells': num_sells, 'Holds': num_holds}\n",
    "    Recommendations = pd.DataFrame(Recoms)\n",
    "    #Recommendations.plot.bar(rot=0)\n",
    "    Recommendations.insert(loc=0,column='ticker',value=ticker)\n",
    "    Recommendations.reset_index(drop=True, inplace=True)\n",
    "    return(Recommendations)\n",
    "\n",
    "#opendf = pd.DataFrame()\n",
    "#for i in tickers:\n",
    "  #  opendf.append(Recommendations)\n",
    "  #  print(opendf)\n",
    "  #  continue\n",
    "#opendf = pd.DataFrame(columns=['ticker','Buys','Sells','Holds'])\n",
    "#for i in tickers: \n",
    "    #opendf = opendf.append(analystrecom(i))\n",
    "    #AnalystRecom = pd.DataFrame(opendf.append(analystrecom(i)))\n",
    "    #print(AnalystRecom)\n",
    "#analystrecom('aapl')\n",
    "def recoms(tickers):\n",
    "    seriesofdf = tickers.apply(analystrecom).values\n",
    "    masterdf = pd.concat(seriesofdf)\n",
    "    masterdf.reset_index(drop=True, inplace=True)\n",
    "    return masterdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "analystrecom('aapl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to show recomendations by year\n",
    "def analystrecom(ticker):\n",
    "    stock = yf.Ticker(ticker)\n",
    "    # Get recommendations from 2020 - Present\n",
    "    data1 = stock.recommendations[::]\n",
    "    data2 = pd.DataFrame(data1['To Grade'])\n",
    "    # Calculate total buys, holds, sells\n",
    "    buys = data2.where((data2=='Buy') | (data2=='Overweight') | (data2=='Outperform') | (data2=='Strong Buy') | (data2=='Positive'))\n",
    "    holds = data2.where((data2=='Neutral') | (data2=='Hold') | (data2=='Market Perform') | (data2=='Equal-Weight') | (data2=='Sector Weight') | (data2=='Sector Perform'))\n",
    "    sells = data2.where((data2=='Sell') | (data2=='Underweight') | (data2=='Underperform'))\n",
    "    # Group by year\n",
    "    yts = data2.asfreq('Y')\n",
    "    # Convert totals to numbers\n",
    "    num_buys = buys.count()\n",
    "    num_holds = holds.count()\n",
    "    num_sells = sells.count()\n",
    "    # Create a dataframe from them\n",
    "    Recoms = pd.DataFrame(data = [num_buys, num_sells, num_holds], columns=['Buys','Holds', 'Sells'])\n",
    "    # # Plotting\n",
    "    # #fig = plt.figure()\n",
    "    # #ax = fig.add_axes([0,0,1,1])\n",
    "    # #values = [num_buys, num_sells, num_holds]\n",
    "    # #recoms = ['Buys', 'Holds', 'Sells']\n",
    "    # #ax.bar(values, recoms)\n",
    "    # #plt.show()\n",
    "    # Recoms = {'Buys': num_buys,'Sells': num_sells, 'Holds': num_holds}\n",
    "    # Recommendations = pd.DataFrame(Recoms)\n",
    "    # #Recommendations.plot.bar(rot=0)\n",
    "    # Recommendations.insert(loc=0,column='ticker',value=ticker)\n",
    "    # Recommendations.reset_index(drop=True, inplace=True)\n",
    "    return yts.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "analystrecom('aapl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install yahoofinancials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahoofinancials import YahooFinancials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# income statement data\n",
    "ticker = 'MSFT'\n",
    "financials = YahooFinancials(ticker)\n",
    "\n",
    "income_stmt = financials.get_financial_stmts('annual', 'income')\n",
    "\n",
    "income_stmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividend history\n",
    "stocks = ['AAPL', 'MSFT', 'JPM', 'INTC']\n",
    "start = '2000-1-1'\n",
    "end = '2015-1-1'\n",
    "financials = YahooFinancials(stocks)\n",
    "dividend_hist = financials.get_daily_dividend_data(start, end)\n",
    "\n",
    "dividend_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning dividend history into dataframe\n",
    "MSFT = dividend_hist['MSFT']\n",
    "\n",
    "MSFTdiv_hist = pd.DataFrame.from_dict(MSFT)\n",
    "\n",
    "MSFTdiv_hist.drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrives stock history with dividends highlighted\n",
    "\n",
    "tick = yf.Ticker(ticker)\n",
    "stock_hist = tick.history(period='10Y')\n",
    "adj_stock_hist = stock_hist[['Close', 'Volume', 'Dividends']]\n",
    "close = adj_stock_hist['Close']\n",
    "volume = adj_stock_hist['Volume']\n",
    "dividends = adj_stock_hist['Dividends']\n",
    "\n",
    "# Plotting the data\n",
    "    # size of plot (needs work)\n",
    "plt.figure(figsize=(20,8))\n",
    "    # content of plot\n",
    "plt.plot(close)\n",
    "    # set plot title, x-label, y-label\n",
    "plt.title(('{} 10 year history').format(ticker))\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.show()\n",
    "\n",
    "# Volume plot\n",
    "plt.figure(figsize=(20,3.3))\n",
    "plt.plot(volume/1000000)\n",
    "plt.title(('Volume of {}').format(ticker))\n",
    "plt.ylabel('Shares traded in millions')\n",
    "plt.xlabel('Time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the volume data\n",
    "fig = plt.figure(figsize=(20,3.3))\n",
    "\n",
    "plt.plot(volume)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "reqyahoo = requests.get('https://www.marketbeat.com/dividends/ex-dividend-date-list/')\n",
    "reqyahoo.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-calculation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a soup for BS4 to work:\n",
    "coverpage = reqyahoo.content\n",
    "yahoosoup = BeautifulSoup(coverpage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverpage_stocklist = yahoosoup.find_all('td', class_='data-sort-value')\n",
    "\n",
    "stock_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-advocacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(0, len(coverpage_stocklist)):\n",
    "    stocks = coverpage_stocklist[i].get_text()\n",
    "    stock_list.append(stocks)\n",
    "    \n",
    "stock_list\n",
    "coverpage_stocklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-ordinance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def future_div_stocks():\n",
    "    # Establish a connection to our site\n",
    "    reqyahoo = requests.get('https://www.marketbeat.com/dividends/ex-dividend-date-list/')\n",
    "    print(reqyahoo.status_code)\n",
    "    if reqyahoo.status_code:\n",
    "        print('Connection sucessful...gathering data...')\n",
    "    \n",
    "    else:\n",
    "        print('Connection was not established... Terminating process')\n",
    "    \n",
    "    # Gather our data\n",
    "    coverpage = reqyahoo.content\n",
    "    yahoosoup = BeautifulSoup(coverpage)\n",
    "    \n",
    "    # Defined data scrapers\n",
    "    coverpage_stocklist = yahoosoup.find_all('div', class_='ticker-area')\n",
    "    getco_names = yahoosoup.find_all('div', class_='title-area')\n",
    "    getex_div_date = yahoosoup.find_all('td', class_='data-sort-value')\n",
    "\n",
    "    \n",
    "    # These need work\n",
    "    getco_names = yahoosoup.find_all('div', class_='title-area')\n",
    "    getex_div_date = yahoosoup.find_all('td', class_='data-sort-value')\n",
    "    \n",
    "    getpayout_freqs = yahoosoup.find_all('div', class_='ticker-area')\n",
    "    getdiv_amount = yahoosoup.find_all('div', class_='ticker-area')\n",
    "    getyeild = yahoosoup.find_all('div', class_='ticker-area')\n",
    "    getex_div_date = yahoosoup.find_all('td', class_='data-sort-value')\n",
    "    getrecord_date = yahoosoup.find_all('div', class_='ticker-area')\n",
    "    getpayable_date = yahoosoup.find_all('div', class_='ticker-area')\n",
    "    \n",
    "    # empty lists and dataframe to store data\n",
    "    future_dividends = pd.DataFrame()\n",
    "    stock_list = []\n",
    "    co_name = []\n",
    "    payout_freq = []\n",
    "    div_amount = []\n",
    "    yeild = []\n",
    "    ex_div_date = []\n",
    "    record_date = []\n",
    "    payable_date = []\n",
    "    \n",
    "    # For loop to gather our stock list\n",
    "    for i in np.arange(0, len(coverpage_stocklist)):\n",
    "        stocks = coverpage_stocklist[i].get_text()\n",
    "        stock_list.append(stocks)\n",
    "    for i in np.arange(0, len(getco_names)):\n",
    "        co_names = getco_names[i].get_text()\n",
    "        co_name.append(co_names)\n",
    "    for i in np.arange(0, len(getex_div_date)):\n",
    "        ex_dates = getex_div_date[i].get_text()\n",
    "        ex_div_date.append(ex_dates)\n",
    "    \n",
    "    return stock_list, co_name, ex_div_date\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-steps",
   "metadata": {},
   "outputs": [],
   "source": [
    "#future_div_stocks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = yahoosoup.find('table')\n",
    "first_td = table.find_all('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-triple",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-horizontal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "def future_div_stocks():\n",
    "    # Establish a connection to our site\n",
    "    reqyahoo = requests.get('https://eresearch.fidelity.com/eresearch/conferenceCalls.jhtml?tab=dividends')\n",
    "    print(reqyahoo.status_code)\n",
    "    if reqyahoo.status_code:\n",
    "        print('Connection sucessful...gathering data...')\n",
    "    \n",
    "    else:\n",
    "        print('Connection was not established... Terminating process')\n",
    "    \n",
    "    # Gather our data\n",
    "    coverpage = reqyahoo.content\n",
    "    yahoosoup = BeautifulSoup(coverpage)\n",
    "    \n",
    "    # Defined data scrapers\n",
    "    coverpage_stocklist = yahoosoup.find_all('td', class_='lft-rt-border center blue-links')\n",
    "    getco_names = yahoosoup.find_all('th', class_='blue-links')\n",
    "    getex_div_date = yahoosoup.find_all('td', class_='data-sort-value')\n",
    "    getdiv_amount = yahoosoup.find_all('td', class_='right')\n",
    "\n",
    "    \n",
    "    # These need work\n",
    "    getco_names = yahoosoup.find_all('div', class_='title-area')\n",
    "    getex_div_date = yahoosoup.find_all('td', class_='data-sort-value')\n",
    "    \n",
    "    getpayout_freqs = yahoosoup.find_all('div', class_='ticker-area')\n",
    "    getdiv_amount = yahoosoup.find_all('div', class_='ticker-area')\n",
    "    getyeild = yahoosoup.find_all('div', class_='ticker-area')\n",
    "    getex_div_date = yahoosoup.find_all('td', class_='data-sort-value')\n",
    "    getrecord_date = yahoosoup.find_all('div', class_='ticker-area')\n",
    "    getpayable_date = yahoosoup.find_all('div', class_='ticker-area')\n",
    "    \n",
    "    # empty lists and dataframe to store data\n",
    "    future_dividends = pd.DataFrame()\n",
    "    stock_list = []\n",
    "    co_name = []\n",
    "    payout_freq = []\n",
    "    div_amount = []\n",
    "    yeild = []\n",
    "    ex_div_date = []\n",
    "    record_date = []\n",
    "    payable_date = []\n",
    "    \n",
    "    # For loop to gather our stock list\n",
    "    for i in np.arange(0, len(coverpage_stocklist)):\n",
    "        stocks = coverpage_stocklist[i].get_text().strip()\n",
    "        stock_list.append(stocks)\n",
    "    #for i in np.arange(0, len(getdiv_amount)):\n",
    "        dividends = getdiv_amount[i].get_text().strip()\n",
    "        div_amount.append(dividends)\n",
    "    for i in np.arange(0, len(getex_div_date)):\n",
    "        ex_dates = getex_div_date[i].get_text()\n",
    "        ex_div_date.append(ex_dates)\n",
    "    \n",
    "    return stock_list, div_amount, ex_div_date\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-threshold",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_div_stocks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-communication",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIVIDEND INFORMATION CALENDAR APP ###\n",
    "\n",
    "# Date and Time handling\n",
    "date = '4/16/2021'\n",
    "date_today = dt.date.today()\n",
    "format_today = date_today.strftime('%m/%d/%Y')\n",
    "csvformat_today = date_today.strftime('%m-%d-%Y')\n",
    "\n",
    "# URL and BS4 handling\n",
    "url = ('https://eresearch.fidelity.com/eresearch/conferenceCalls.jhtml?tab=dividends&begindate={}'.format(format_today))\n",
    "geturl = requests.get(url)\n",
    "print(geturl.status_code)\n",
    "coverpage = geturl.content\n",
    "yahoosoup = BeautifulSoup(coverpage)\n",
    "\n",
    "# Ticker information\n",
    "ticker_list = []\n",
    "def generate_report():\n",
    "    # Ticker information\n",
    "    html_tickerinfo = yahoosoup.find_all('td', class_='lft-rt-border center blue-links')\n",
    "    try:\n",
    "        for symbol in html_tickerinfo:\n",
    "            # print(html_tickerinfo)\n",
    "            ticker_list.append(symbol.a.contents[0])\n",
    "            tickers_df = pd.DataFrame(ticker_list, columns=['Ticker'])\n",
    "    except:\n",
    "        for symbol in html_tickerinfo:\n",
    "            # print(html_tickerinfo)\n",
    "            print((symbol.a))\n",
    "            ticker_list.append(symbol.a)\n",
    "            tickers_df = pd.DataFrame(ticker_list, columns=['Ticker'])\n",
    "        ticker_col = pd.Series(tickers_df['Ticker'])\n",
    "        #print(ticker_col)\n",
    "    \n",
    "\n",
    "    # Ex-dividend date information\n",
    "    ex_div_dates_df = pd.DataFrame()\n",
    "    len_tickers = len(tickers_df)\n",
    "    \n",
    "    ex_date_list = list(itertools.repeat(format_today, len_tickers))\n",
    "    ex_div_dates_df.insert(0, 'Ex-Date', ex_date_list)\n",
    "    \n",
    "    #ex_div_dates.append()\n",
    "\n",
    "# Dividend Amount information\n",
    "    dividend_list = []\n",
    "    html_divs = yahoosoup.find_all('td', class_='right')\n",
    "    for div in html_divs:\n",
    "        dividend_list.append(div.contents[0])\n",
    "        dividend_df = pd.DataFrame(dividend_list, columns=['Dividends'])\n",
    "        \n",
    "# Record Date information\n",
    "\n",
    "\n",
    "\n",
    "# Pay Date information\n",
    "    pay_days = []\n",
    "    html_pay_dates = yahoosoup.find_all('td', class_='lft-rt-border')\n",
    "    #for dates in html_pay_dates:\n",
    "        #print(dates.td.con)\n",
    "\n",
    "\n",
    "\n",
    "# Join and merge all information to one dataframe\n",
    "    frames = [tickers_df, dividend_df, ex_div_dates_df]\n",
    "    \n",
    "    masterframe = pd.concat(frames, axis=1)\n",
    "    master_df = pd.DataFrame(masterframe)\n",
    "    \n",
    "    #return masterframe\n",
    "    \n",
    "    # Write the master dataframe to csv file\n",
    "    # masterframe.to_csv(('CSVfiles/{}_Dividend_list').format(format_today))\n",
    "    masterframe.to_csv('CSVfiles/test{}.csv'.format(csvformat_today))\n",
    "    return master_df\n",
    "\n",
    "# Additional Financial information module\n",
    "    #ticks = pd.DataFrame(ticker_col)\n",
    "    \n",
    "    #print(ticks.values)\n",
    "    \n",
    "\n",
    "generate_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-toronto",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIVIDEND INFORMATION CALENDAR APP ### TEST ENV\n",
    "\n",
    "# Date and Time handling\n",
    "date = '4/16/2021'\n",
    "date_today = dt.date.today()\n",
    "format_today = date_today.strftime('%m/%d/%Y')\n",
    "\n",
    "# URL and BS4 handling\n",
    "url = ('https://eresearch.fidelity.com/eresearch/conferenceCalls.jhtml?tab=dividends&begindate={}'.format(format_today))\n",
    "geturl = requests.get(url)\n",
    "print(geturl.status_code)\n",
    "coverpage = geturl.content\n",
    "yahoosoup = BeautifulSoup(coverpage)\n",
    "\n",
    "# Ticker information\n",
    "ticker_list = []\n",
    "def generate_report():\n",
    "    # Ticker information\n",
    "    html_tickerinfo = yahoosoup.find_all('td', class_='lft-rt-border center blue-links')\n",
    "    try:\n",
    "        for symbol in html_tickerinfo:\n",
    "            # print(html_tickerinfo)\n",
    "            ticker_list.append(symbol.a.contents[0])\n",
    "            tickers_df = pd.DataFrame(ticker_list, columns=['Ticker'])\n",
    "    except:\n",
    "        for symbol in html_tickerinfo:\n",
    "            # print(html_tickerinfo)\n",
    "            ticker_list.append(symbol.a)\n",
    "            tickers_df = pd.DataFrame(ticker_list, columns=['Ticker'])\n",
    "    \n",
    "\n",
    "    # Ex-dividend date information\n",
    "    ex_div_dates_df = pd.DataFrame()\n",
    "    len_tickers = len(tickers_df)\n",
    "    \n",
    "    ex_date_list = list(itertools.repeat(format_today, len_tickers))\n",
    "    ex_div_dates_df.insert(0, 'Ex-Date', ex_date_list)\n",
    "    \n",
    "    print(len_tickers)\n",
    "    \n",
    "    #ex_div_dates.append()\n",
    "\n",
    "# Dividend Amount information\n",
    "    dividend_list = []\n",
    "    html_divs = yahoosoup.find_all('td', class_='right')\n",
    "    for div in html_divs:\n",
    "        dividend_list.append(div.contents[0])\n",
    "        dividend_df = pd.DataFrame(dividend_list, columns=['Dividends'])\n",
    "        \n",
    "# Record Date information\n",
    "\n",
    "\n",
    "\n",
    "# Pay Date information\n",
    "    pay_days = []\n",
    "    html_pay_dates = yahoosoup.find_all('td', class_='lft-rt-border')\n",
    "    #for dates in html_pay_dates:\n",
    "        #print(dates.td.con)\n",
    "\n",
    "\n",
    "\n",
    "# Join and merge all information to one dataframe\n",
    "    frames = [tickers_df, dividend_df, ex_div_dates_df]\n",
    "    \n",
    "    masterframe = pd.concat(frames, axis=1)\n",
    "    return masterframe\n",
    "\n",
    "generate_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdf = pd.DataFrame()\n",
    "\n",
    "date = '4/13/2021'\n",
    "url = ('https://eresearch.fidelity.com/eresearch/conferenceCalls.jhtml?tab=dividends&begindate={}'.format(date))\n",
    "\n",
    "reqyahoo = requests.get(url)\n",
    "coverpage = reqyahoo.content\n",
    "yahoosoup = BeautifulSoup(coverpage)\n",
    "getdiv_amount = yahoosoup.find_all('td', class_='right')\n",
    "get_ticker = yahoosoup.find_all('td', class_='lft-rt-border center blue-links')\n",
    "\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets tickers for day\n",
    "ticker_list = []\n",
    "def get_tickers():\n",
    "    html_tickerinfo = yahoosoup.find_all('td', class_='lft-rt-border center blue-links')\n",
    "    for symbol in html_tickerinfo:\n",
    "        ticker_list.append(symbol.a.contents[0])\n",
    "    return ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tickers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-mention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets ex-div date for tickers for day\n",
    "exdiv_list = []\n",
    "def get_exdates():\n",
    "    html_exdiv_info = yahoosoup.find_all('td', class_='lft-rt-border')\n",
    "    for date in html_exdiv_info:\n",
    "        exdiv_list.append(date.contents[0])\n",
    "    return exdiv_list\n",
    "\n",
    "get_exdates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-gibson",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = extracting.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-microwave",
   "metadata": {},
   "outputs": [],
   "source": [
    "listd = []\n",
    "import re\n",
    "for n in np.arange(splits):\n",
    "    dividend_fromstr = [float(s) for s in re.findall(r'-?\\d+\\.?\\d*', splits[n])]\n",
    "    listd.append(dividend_fromstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-climate",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WEEKLY EARNINGS AND REPORTING INFORMATION ###\n",
    "\n",
    "\n",
    "# List of companies reporting earnings this week\n",
    "\n",
    "\n",
    "\n",
    "# List of companies reporting earnings NEXT week\n",
    "\n",
    "\n",
    "# Options data showing market maker predictions and ranges of possibilty\n",
    "\n",
    "\n",
    "\n",
    "### WEEKLY SEC FILING NEWS ###\n",
    "\n",
    "\n",
    "# Unusual & Unique Filings\n",
    "\n",
    "\n",
    "# Insider trades\n",
    "\n",
    "\n",
    "# Notes & Supplemental information\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "homeless-douglas",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data 'March 5 2020' does not match format '%b %d %Y %I:%M%p'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-65441b13c91c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0myahoo_earnings_calendar\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mYahooEarningsCalendar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m date_from = datetime.datetime.strptime(\n\u001b[0m\u001b[0;32m      5\u001b[0m     'March 5 2020', '%b %d %Y %I:%M%p')\n\u001b[0;32m      6\u001b[0m date_to = datetime.datetime.strptime(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\financialintel\\lib\\_strptime.py\u001b[0m in \u001b[0;36m_strptime_datetime\u001b[1;34m(cls, data_string, format)\u001b[0m\n\u001b[0;32m    566\u001b[0m     \"\"\"Return a class cls instance based on the input string and the\n\u001b[0;32m    567\u001b[0m     format string.\"\"\"\n\u001b[1;32m--> 568\u001b[1;33m     \u001b[0mtt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfraction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgmtoff_fraction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_strptime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m     \u001b[0mtzname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgmtoff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfraction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\financialintel\\lib\\_strptime.py\u001b[0m in \u001b[0;36m_strptime\u001b[1;34m(data_string, format)\u001b[0m\n\u001b[0;32m    347\u001b[0m     \u001b[0mfound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat_regex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         raise ValueError(\"time data %r does not match format %r\" %\n\u001b[0m\u001b[0;32m    350\u001b[0m                          (data_string, format))\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_string\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data 'March 5 2020' does not match format '%b %d %Y %I:%M%p'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from yahoo_earnings_calendar import YahooEarningsCalendar\n",
    "\n",
    "date_from = datetime.datetime.strptime(\n",
    "    'March 5 2020', '%b %d %Y %I:%M%p')\n",
    "date_to = datetime.datetime.strptime(\n",
    "    'March 30 2020  1:00PM', '%b %d %Y %I:%M%p')\n",
    "yec = YahooEarningsCalendar()\n",
    "#print(yec.earnings_on(date_from)) \n",
    "march_earnings = yec.earnings_between(date_from, date_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accredited-regard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yahoo_fin.stock_info as si\n",
    "\n",
    "# Get Earnings history for ticker\n",
    "ticker = 'NVDA'\n",
    "\n",
    "# Download Earnings history\n",
    "stock_earnings = si.get_earnings_history(ticker)\n",
    "\n",
    "# Turn earnings list into dataframe\n",
    "earnings_frame = pd.DataFrame.from_dict(stock_earnings)\n",
    "\n",
    "# Get next earnings dates\n",
    "next_earnings = si.get_next_earnings_date(ticker)\n",
    "\n",
    "# Get eanrings data from specific date\n",
    "earnings_next_wk = si.get_earnings_for_date('04/20/2021')\n",
    "\n",
    "# put in dataframe\n",
    "earningsframes = pd.DataFrame(earnings_next_wk)\n",
    "\n",
    "# Get earnings with date range\n",
    "earnings_this_week = si.get_earnings_in_date_range('04/25/2021', '04/30/2021')\n",
    "\n",
    "# put in dataframe\n",
    "earnings_thiswk = pd.DataFrame(earnings_this_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "alert-highway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>companyshortname</th>\n",
       "      <th>startdatetime</th>\n",
       "      <th>startdatetimetype</th>\n",
       "      <th>epsestimate</th>\n",
       "      <th>epsactual</th>\n",
       "      <th>epssurprisepct</th>\n",
       "      <th>timeZoneShortName</th>\n",
       "      <th>gmtOffsetMilliSeconds</th>\n",
       "      <th>quoteType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMKR</td>\n",
       "      <td>Amkor Technology Inc</td>\n",
       "      <td>2021-04-26T20:00:00.000Z</td>\n",
       "      <td>AMC</td>\n",
       "      <td>0.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EDT</td>\n",
       "      <td>-14400000</td>\n",
       "      <td>EQUITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AXTA</td>\n",
       "      <td>Axalta Coating Systems Ltd</td>\n",
       "      <td>2021-04-26T20:00:00.000Z</td>\n",
       "      <td>AMC</td>\n",
       "      <td>0.42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EDT</td>\n",
       "      <td>-14400000</td>\n",
       "      <td>EQUITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMP</td>\n",
       "      <td>Ameriprise Financial Inc</td>\n",
       "      <td>2021-04-26T20:00:00.000Z</td>\n",
       "      <td>AMC</td>\n",
       "      <td>4.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EDT</td>\n",
       "      <td>-14400000</td>\n",
       "      <td>EQUITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PKG</td>\n",
       "      <td>Packaging Corp of America</td>\n",
       "      <td>2021-04-26T20:00:00.000Z</td>\n",
       "      <td>AMC</td>\n",
       "      <td>1.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EDT</td>\n",
       "      <td>-14400000</td>\n",
       "      <td>EQUITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ARE</td>\n",
       "      <td>Alexandria Real Estate Equities Inc</td>\n",
       "      <td>2021-04-26T20:00:00.000Z</td>\n",
       "      <td>AMC</td>\n",
       "      <td>0.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EDT</td>\n",
       "      <td>-14400000</td>\n",
       "      <td>EQUITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>PNM</td>\n",
       "      <td>PNM Resources Inc</td>\n",
       "      <td>2021-04-30T12:30:00.000Z</td>\n",
       "      <td>BMO</td>\n",
       "      <td>0.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EDT</td>\n",
       "      <td>-14400000</td>\n",
       "      <td>EQUITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>VSQTF</td>\n",
       "      <td>Victory Square Technologies Inc</td>\n",
       "      <td>2021-04-30T10:59:00.000Z</td>\n",
       "      <td>TNS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EDT</td>\n",
       "      <td>-14400000</td>\n",
       "      <td>EQUITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>OIIM</td>\n",
       "      <td>O2micro International Ltd</td>\n",
       "      <td>2021-04-30T12:30:00.000Z</td>\n",
       "      <td>BMO</td>\n",
       "      <td>0.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EDT</td>\n",
       "      <td>-14400000</td>\n",
       "      <td>EQUITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>LAZ</td>\n",
       "      <td>Lazard Ltd</td>\n",
       "      <td>2021-04-30T12:30:00.000Z</td>\n",
       "      <td>BMO</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EDT</td>\n",
       "      <td>-14400000</td>\n",
       "      <td>EQUITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>SHLX</td>\n",
       "      <td>Shell Midstream Partners LP</td>\n",
       "      <td>2021-04-30T12:30:00.000Z</td>\n",
       "      <td>BMO</td>\n",
       "      <td>0.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EDT</td>\n",
       "      <td>-14400000</td>\n",
       "      <td>EQUITY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>896 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker                     companyshortname             startdatetime  \\\n",
       "0     AMKR                 Amkor Technology Inc  2021-04-26T20:00:00.000Z   \n",
       "1     AXTA           Axalta Coating Systems Ltd  2021-04-26T20:00:00.000Z   \n",
       "2      AMP             Ameriprise Financial Inc  2021-04-26T20:00:00.000Z   \n",
       "3      PKG            Packaging Corp of America  2021-04-26T20:00:00.000Z   \n",
       "4      ARE  Alexandria Real Estate Equities Inc  2021-04-26T20:00:00.000Z   \n",
       "..     ...                                  ...                       ...   \n",
       "891    PNM                    PNM Resources Inc  2021-04-30T12:30:00.000Z   \n",
       "892  VSQTF      Victory Square Technologies Inc  2021-04-30T10:59:00.000Z   \n",
       "893   OIIM            O2micro International Ltd  2021-04-30T12:30:00.000Z   \n",
       "894    LAZ                           Lazard Ltd  2021-04-30T12:30:00.000Z   \n",
       "895   SHLX          Shell Midstream Partners LP  2021-04-30T12:30:00.000Z   \n",
       "\n",
       "    startdatetimetype  epsestimate  epsactual  epssurprisepct  \\\n",
       "0                 AMC         0.46        NaN             NaN   \n",
       "1                 AMC         0.42        NaN             NaN   \n",
       "2                 AMC         4.69        NaN             NaN   \n",
       "3                 AMC         1.46        NaN             NaN   \n",
       "4                 AMC         0.58        NaN             NaN   \n",
       "..                ...          ...        ...             ...   \n",
       "891               BMO         0.20        NaN             NaN   \n",
       "892               TNS          NaN        NaN             NaN   \n",
       "893               BMO         0.09        NaN             NaN   \n",
       "894               BMO         0.89        NaN             NaN   \n",
       "895               BMO         0.35        NaN             NaN   \n",
       "\n",
       "    timeZoneShortName  gmtOffsetMilliSeconds quoteType  \n",
       "0                 EDT              -14400000    EQUITY  \n",
       "1                 EDT              -14400000    EQUITY  \n",
       "2                 EDT              -14400000    EQUITY  \n",
       "3                 EDT              -14400000    EQUITY  \n",
       "4                 EDT              -14400000    EQUITY  \n",
       "..                ...                    ...       ...  \n",
       "891               EDT              -14400000    EQUITY  \n",
       "892               EDT              -14400000    EQUITY  \n",
       "893               EDT              -14400000    EQUITY  \n",
       "894               EDT              -14400000    EQUITY  \n",
       "895               EDT              -14400000    EQUITY  \n",
       "\n",
       "[896 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earnings_thiswk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-teacher",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-opening",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
